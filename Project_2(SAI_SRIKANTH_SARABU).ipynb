{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Project-2(SAI SRIKANTH SARABU).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MZtHZZdnQ4R8"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZtHZZdnQ4R8"
      },
      "source": [
        "#SAI SRIKANTH SARABU\n",
        "#A20343781 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ9n5hR-O_bV"
      },
      "source": [
        "# Project-2: Locality Sensitive Hashing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALeXRGEUO_bW"
      },
      "source": [
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from random import randrange\n",
        "from shutil import copyfile"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsLcHwqjQ-Iz",
        "outputId": "cc714524-c424-4a39-de6e-c631f8005216"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu8XFDfYO_bW"
      },
      "source": [
        "Suspicious datasets for this project will be in <b>Suspicious</b> directory\n",
        "\n",
        "\n",
        "Your query datasets will be in <b>Original</b> directory\n",
        "\n",
        "\n",
        "You have to use any one original Wikipedia article from <b>Original</b> for <b>Fact Checks</b> steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjK3Y-RhO_bX",
        "outputId": "73ffef91-d4c9-4f28-ff82-a19bc8270dc3"
      },
      "source": [
        "data = '/content/drive/MyDrive/corpus_data/' \n",
        "\n",
        "#creating 2 directories with Suspicious and Original as their name and placing the files respectively\n",
        "try:\n",
        "  os.mkdir('Suspicious')\n",
        "  os.mkdir('Original')\n",
        "except:\n",
        "  print('folders already created')\n",
        "\n",
        "for f in os.listdir(data):\n",
        "  if 'orig' in f:\n",
        "    copyfile(data + f, 'Original/'+f)\n",
        "  else:\n",
        "    copyfile(data + f, 'Suspicious/'+f)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "folders already created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tSdo6U0O_bX"
      },
      "source": [
        "### STEP - 1: Shingling (20 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK01_mqIO_bX"
      },
      "source": [
        "# Type your code here... \n",
        "# Create necessary number of cells below this cell\n",
        "k = 3\n",
        "\n",
        "# NOTE: No complex text processing is required\n",
        "# convert just upper case characters to lower case\n",
        "\n",
        "original_path = '/content/Original'\n",
        "suspicious_path = '/content/Suspicious'\n",
        "\n",
        "uniquek3shingles = set()                    #Created 3 empty sets for 3, 4 and 5 unique shingles\n",
        "uniquek4shingles = set()\n",
        "uniquek5shingles = set()\n",
        "paths = [suspicious_path, original_path]    \n",
        "\n",
        "#Below for loop with traverse through all the documents both Original and Suspicious and create 3, 4 and 5 shingles.\n",
        "for path in paths:                          \n",
        "  for file in os.listdir(path):\n",
        "    k=3\n",
        "    with open(os.path.join(path, file), \"r\",encoding ='utf8',errors='ignore') as filename:     #reading each file from folder\n",
        "      pList = filename.read()\n",
        "      wList = pList.split()                             #splits the file into words and stored into the list\n",
        "    for i in range(len(wList)-k+1):                     #looping through all the words\n",
        "      w = wList[i:i + k]                                #creating the 3 words list \n",
        "      x = ' '.join(w).lower()                           #concatenating them with space separated \n",
        "      uniquek3shingles.add(x)                           #adding to the set\n",
        "    k=4                                                 #increment k\n",
        "    for i in range(len(wList)-k+1):                     #below 2 loops also perform same with k incremented\n",
        "      w = wList[i:i + k]\n",
        "      x = ' '.join(w).lower()\n",
        "      uniquek4shingles.add(x)\n",
        "    k=5\n",
        "    for i in range(len(wList)-k+1):\n",
        "      w = wList[i:i + k]\n",
        "      x = ' '.join(w).lower()\n",
        "      uniquek5shingles.add(x)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "0MLXN51VO_bY"
      },
      "source": [
        "Report results (number of unique k-shingles) for k={3,4,5} below:\n",
        "1. k=3:\n",
        "2. k=4:\n",
        "3. k=5:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqWWeF5zZ97R",
        "outputId": "31942bb9-af57-4c59-bc4c-e294f58b480b"
      },
      "source": [
        "print('Number of unique 3-shingles are:',len(uniquek3shingles))\n",
        "print('Number of unique 4-shingles are:',len(uniquek4shingles))\n",
        "print('Number of unique 5-shingles are:',len(uniquek5shingles))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique 3-shingles are: 13724\n",
            "Number of unique 4-shingles are: 15127\n",
            "Number of unique 5-shingles are: 15796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkYHjBrMO_bY",
        "outputId": "b5732e62-2c05-4ca0-a874-cfb959d39017"
      },
      "source": [
        "# Type your code to get the 5-shingle index here\n",
        "shingleIndex5 = {}      #created 2 dictionaries one stores 5 shingles of each file from suspicious folder, other \n",
        "OrignalIndex5 = {}      #stores 5 shingles from each orginal file \n",
        "for path in paths:\n",
        "  for file in os.listdir(path):                        \n",
        "    with open(os.path.join(path, file), \"r\",encoding ='utf8',errors='ignore') as filename:\n",
        "      pList = filename.read().lower()       \n",
        "      wList = pList.split()\n",
        "      k=5\n",
        "    k5shinglesIndex = set()                     #created temporary set to store shingles from each file\n",
        "    for i in range(len(wList)-k+1):\n",
        "      w = wList[i:i + k]\n",
        "      x = ' '.join(w).lower()\n",
        "      k5shinglesIndex.add(x)\n",
        "    if 'orig' in file:                          #checking the file name and placing the shingles in respective dictionary\n",
        "      OrignalIndex5[file] = list(k5shinglesIndex)   #making shingle into list and adding to a dictionary with key as file name\n",
        "    else:\n",
        "      shingleIndex5[file] = list(k5shinglesIndex)\n",
        "\n",
        "uniquek5shinglesList = list(uniquek5shingles)   #converting set of all files 5 shingles to set.\n",
        "uniquek5shinglesList"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['splitting the programming into optimal',\n",
              " 'try to fool the search',\n",
              " 'further vector space models, basically',\n",
              " 'for that page. the pagerank',\n",
              " 'also be refered to as',\n",
              " 'time he accidently records the',\n",
              " 'of the train and car',\n",
              " 'categorization is a powerful mechanism',\n",
              " 'space model include: generalized vector',\n",
              " 'failure of the vector space',\n",
              " 'the definition of term depends',\n",
              " 'classes and to go into',\n",
              " 'is not sufficiently mature, may',\n",
              " 'modify since they do not',\n",
              " 'simpler term count model the',\n",
              " 'a zero value for the',\n",
              " 'for many programmerers when developing',\n",
              " 'observations, for instance the probability',\n",
              " 'vectors will not have any',\n",
              " 'existing code without modification. inheritance',\n",
              " 'is still a good indicator',\n",
              " 'a number of other models',\n",
              " 'exposed by ancestor, or by',\n",
              " 'not have much in common.',\n",
              " 'original form of pagerank initial',\n",
              " 'classes). categorization in computer languages',\n",
              " 'and had no match which',\n",
              " 'probability requires that (1) where',\n",
              " 'the pagerank depends on the',\n",
              " 'a sub-problem is encountered again',\n",
              " 'the link which is assigns',\n",
              " 'other similar reciprocal hyperlinking schemes.',\n",
              " 'used to subclass another. also,',\n",
              " 'developed by google to provide',\n",
              " 'number of pages, dampening factor,',\n",
              " 'however whilst vector space modelling',\n",
              " 'or more methods exposed by',\n",
              " 'allows new classes to be',\n",
              " 'all pages was the total',\n",
              " 'to find out the same',\n",
              " 'capacity would be a class',\n",
              " 'and then used to create',\n",
              " 'an observation that a patient',\n",
              " 'path, as shown in figure',\n",
              " 'an object of one of',\n",
              " 'is patented by stanford university.',\n",
              " 'or longer phrases. the dimensionality',\n",
              " 'nature of the pagerank system,',\n",
              " 'of a certain page is',\n",
              " 'this is 60%, or 0.6.',\n",
              " 'and for metadata about documents,',\n",
              " 'table containing the number of',\n",
              " 'typical example could be of',\n",
              " 'calculate the probability of b',\n",
              " 'and all subclasses of circle,',\n",
              " 'a lot of code reducing',\n",
              " 'to a separate term. a',\n",
              " 'compute the probability that, given',\n",
              " 'colour = newcolour; } }',\n",
              " 'anymore, we can throw it',\n",
              " \"information-theoretic criteria, eliminate non-content-bearing ``high-frequency''\",\n",
              " 'frequencies within the document and',\n",
              " 'this allows them to see',\n",
              " 'then your site is considered',\n",
              " 'others that have a high',\n",
              " 'probability of a. it is',\n",
              " 'and even in such cases,',\n",
              " 'may waste to,e recomputing optimal',\n",
              " 'however, the private variable colour',\n",
              " 'using the formula is 0.25.',\n",
              " 'he refined his method to',\n",
              " 'engines used highest keyword density,',\n",
              " 'in mathematics and computer science,',\n",
              " 'of an optimal solution. secondly',\n",
              " 'to,e recomputing optimal solutions to',\n",
              " 'vertex in a graph. first,',\n",
              " 'page link to a, then',\n",
              " 'to have certain symptoms. bayes',\n",
              " 'the number of times a',\n",
              " 'relationships between one object and',\n",
              " 'the vector space vector space',\n",
              " 'queries. our approach has practical',\n",
              " 'little or no modification at',\n",
              " 'field was founded as a',\n",
              " 'also called the pagerank of',\n",
              " 'that the term programming in',\n",
              " 'vector by the modulus of',\n",
              " 'into methods of avoiding links',\n",
              " 'is one of the most',\n",
              " 'computer science and mathematics, dynamic',\n",
              " 'compress data in high density',\n",
              " 'that page, taking into account',\n",
              " 'a mathematical \"bag\" structure, recording',\n",
              " 'is derived from a theoretical',\n",
              " 'fibonacci sequence; f3 = f1',\n",
              " 'x=(x1,...,xm) and y=(y1,...,yn) find a',\n",
              " 'a and b. for example:',\n",
              " 'most - and quite frequently',\n",
              " 'number of wighting sceems which',\n",
              " 'other details whilst full time',\n",
              " 'random events. it is mainly',\n",
              " 'the solution to the problem',\n",
              " 'the theoretical true value. a',\n",
              " 'from another class, all the',\n",
              " 'is therefore used to create',\n",
              " 'uncertainty, while frequentists assign probabilities',\n",
              " 'the name vector space model.',\n",
              " 'operations including scoring documents on',\n",
              " 'thomas bayes) provides relation between',\n",
              " 'as a vector, each dimension',\n",
              " 'certain symptoms. bayes theorem can',\n",
              " 'a different term. if a',\n",
              " 'to create solutions to larger',\n",
              " 'this is highly used in',\n",
              " 'code to be used again',\n",
              " 'random events. it is often',\n",
              " 'the corpus. relevancy ranks for',\n",
              " 'considered that fruit is an',\n",
              " 'a probability is expressed as',\n",
              " 'them to see whether their',\n",
              " 'is counter hackers influence on',\n",
              " 'memoization dynamic programming usually takes',\n",
              " 'vector space model is one',\n",
              " 'are 4 key problems with',\n",
              " 'possibilities (which ensures correctness) whilst',\n",
              " 'methods (walking, mating, etc.). they',\n",
              " 'debates in greater detail. frequentists',\n",
              " 'term used for this replacing',\n",
              " 'values, hence the frequent recalculating',\n",
              " '– if your site is',\n",
              " 'to all types of buildings.',\n",
              " 's can be estimated from',\n",
              " 'another. for instance two classes,',\n",
              " 'log and alternate log as',\n",
              " 'way variables relate to each',\n",
              " 'objects. for instance, a \"fruit\"',\n",
              " 'avoid having to recomputed (leading',\n",
              " 'degrees of uncertainty. the articles',\n",
              " 'on the same topic wont',\n",
              " 'is to find the best',\n",
              " 'that an employee who tested',\n",
              " 'solve the same problem later,',\n",
              " 'can be treated (cast) to',\n",
              " 'and substrings of words might',\n",
              " 'tool which provides a number',\n",
              " 'is fundamental to a host',\n",
              " 'algorithm to artificially increase their',\n",
              " 'derived classes, inherit attributes and',\n",
              " 'in the vector is the',\n",
              " 'accurate. this method is far',\n",
              " 'generalise the structure of an',\n",
              " 'words occurring in the corpus.',\n",
              " 'world, there are many algorithms',\n",
              " 'from gathering vast amounts of',\n",
              " 'valid in all universal interpretations',\n",
              " 'the ‘postgraduate’ and ‘student classes’.',\n",
              " 'of the vector, if words',\n",
              " 'optimal substructure. the method is',\n",
              " 'common factors and these would',\n",
              " 'the solution to a subproblem',\n",
              " 'in all popular interpretations of',\n",
              " 'links are linked to from',\n",
              " \"given a. bayes' theorem relates\",\n",
              " 'and therefore reducing the complexity',\n",
              " 'which is used to subclass',\n",
              " 'about each specific entity except',\n",
              " 'elsewhere within the program. to',\n",
              " 'information within documents and for',\n",
              " 'classes (instances of which are',\n",
              " 'superclass or parent class whereas,',\n",
              " 'the shape class, which means',\n",
              " 'can also be termed as',\n",
              " 'can be abused when people',\n",
              " 'tries to follow the intentional',\n",
              " 'events at an exhibition. this',\n",
              " 'not to occur (p)=0.5: event',\n",
              " 'currently at the centre of',\n",
              " 'main problem is divided into',\n",
              " 'basically the words or any',\n",
              " 'of course can be sub-divided',\n",
              " 'and methods are available to',\n",
              " 'document frequency model. in this',\n",
              " 'students can only wear skirts',\n",
              " 'approach is called memoization (not',\n",
              " 'independently of the order in',\n",
              " 'problem. by solving subproblems in',\n",
              " 'computing these values, also known',\n",
              " '(or inherit) attribute and behaviour',\n",
              " 'approach which represents documents as',\n",
              " 'to any numbr of entities',\n",
              " 'increased enormously. for example, in',\n",
              " 'a key role in the',\n",
              " 'dynamic programming is a method',\n",
              " 'stated by the reverend thomas',\n",
              " '6,285,999 ). nevertheless, the patent',\n",
              " 'can be expressed independently of',\n",
              " 'system into giving their pages',\n",
              " 'class. inheritance is a core',\n",
              " 'can share lots of code.',\n",
              " 'relates the conditional and marginal',\n",
              " 'waste to,e recomputing optimal solutions',\n",
              " 'model was put forward by',\n",
              " 'a subclass and a superclass.',\n",
              " 'a method that combines memorization',\n",
              " 'dynamic programming is to determine',\n",
              " 'contest – if your site',\n",
              " 'probability which is usually interested',\n",
              " 'if your site is linked',\n",
              " 'bayes’ theorem is also often',\n",
              " 'index terms. it is used',\n",
              " 'spamming and a lot of',\n",
              " \"in which one's beliefs about\",\n",
              " 'common interpretations of probability. for',\n",
              " 'available today. most of these',\n",
              " 'have in base class or',\n",
              " 'to form new classes using',\n",
              " 'learning by the means of',\n",
              " 'another. the field was founded',\n",
              " 'blog comments and message boards.',\n",
              " 'the entire set of documents.',\n",
              " 'schemes is tf-idf weighting (see',\n",
              " 'for instance index terms. its',\n",
              " 'in computer science and can',\n",
              " 'be changed when a new',\n",
              " 'programming is a faster method',\n",
              " 'model has limitations. long documents',\n",
              " 'subproblems, a naive approach may',\n",
              " 'by shared control code. inheritance',\n",
              " 'as proportions of the whole,',\n",
              " 'be a relatively accurate test.',\n",
              " 'and references. the weight taking',\n",
              " \"p(b|a)p(a) + p(b|a')p(a') where '\",\n",
              " 'is advantageous to differentiate between',\n",
              " 'of a program since modules',\n",
              " 'little or no modification. inheritance',\n",
              " 'other topics such as history,',\n",
              " 'the terms. however whilst vector',\n",
              " 't is relevant to the',\n",
              " 'across once more, this would',\n",
              " 'object oriented programming where a',\n",
              " 'by pr(e). the name \"pagerank\"',\n",
              " 'non-vanishing probability: p(a|b) = \\\\frac{p(b',\n",
              " 'human learning by means of',\n",
              " 'a \"false positive match\"; *',\n",
              " 'sub-problem may not affect the',\n",
              " 'mechanism by some examples: like',\n",
              " 'scale. the pagerank of a',\n",
              " 'x minutes in direction y.',\n",
              " 'assigns a numeric weighting from',\n",
              " 'systems analysis and engineering topic',\n",
              " 'extend keyword, which is used',\n",
              " 'contents of a text. furthermore,',\n",
              " 'term varies. single words, keywords',\n",
              " 'be worked out by comparing',\n",
              " 'so called ‘bottom-up’ approach, meaning',\n",
              " 'was implemented. instead google uses',\n",
              " 'that the damping factor will',\n",
              " 'calculating conditional probabilities such as',\n",
              " 'every 3 to 6 months,',\n",
              " 'query the search space, the',\n",
              " 'computational process. pagerank can be',\n",
              " 'very similar interfaces can share',\n",
              " '+ f2 and f4 =',\n",
              " 'genetic inheritance where a child',\n",
              " 'vector space model was first',\n",
              " 'also to rank the relevancy',\n",
              " 'in the document then its',\n",
              " 'treated (cast) to living things.',\n",
              " 'and methods of its superclass.',\n",
              " 'the original, or superclass. because',\n",
              " 'top-down approach breaks the problem',\n",
              " 'solving mathematical programming problems that',\n",
              " 'that child class has all',\n",
              " 'factors, but it is generally',\n",
              " 'on a number of factors:',\n",
              " 'prob(b|a) * prob(a) /prob(b), it',\n",
              " 'this example, the building would',\n",
              " 'called fulltime and part time.',\n",
              " 'relation can be created. on',\n",
              " 'words\" - a standard information',\n",
              " 'considered the superclass – it',\n",
              " 'terms are single words, keywords,',\n",
              " 'resulting in a \"false negative',\n",
              " \"we'll need in advance. dynamic\",\n",
              " 'parent- or super-class. the concept',\n",
              " 'method in a table. the',\n",
              " 'matches may be returned if',\n",
              " \"way in which one's recognition\",\n",
              " 'the other hand, inheritance is',\n",
              " 'of a linked page divided',\n",
              " 'the reverend thomas bayes (1702–1761),',\n",
              " 'utilised variously in indexing, information',\n",
              " 'thomas bayes (1702–1761), who studied',\n",
              " 'of prob(ab) from prob(ba). statistical',\n",
              " 'approach, the problem is broken',\n",
              " 'define value of optimal solution',\n",
              " 'links to others. deep, links',\n",
              " 'for example, a schedule of',\n",
              " 'structure of an object, inheritance',\n",
              " 'and the probability of both',\n",
              " 'probability of a, p(b) is',\n",
              " 'retrieval. it was first used',\n",
              " 'a website. page ranks can',\n",
              " 'conventional name: * p(a) is',\n",
              " \"called bayes' law) connects the\",\n",
              " 'probability. it plays a central',\n",
              " 'inheritance hierarchy of an object',\n",
              " 'from stanford university. in other',\n",
              " 'the documents from which the',\n",
              " 'this is because it allows',\n",
              " 'theorem was names after rev',\n",
              " 'access to an object, it',\n",
              " 'be sets. conditional probability requires',\n",
              " 'just have salary and part',\n",
              " 'optimization. thus, the program is',\n",
              " 'terms, the number of dimensions',\n",
              " 'how bayes’ theorem plays a',\n",
              " '0.5 pagerank. simplified algorithm how',\n",
              " 'their theories of evidence and',\n",
              " 'optimal solutions of the overall',\n",
              " 'can be used to find',\n",
              " \"intuitively, bayes' theorem in this\",\n",
              " 'behaviours (functions) that are common',\n",
              " 'to save time the solutions',\n",
              " 'little or no modification. an',\n",
              " 'paper.[4] in practice, the pagerank',\n",
              " 'match\"; similar context documents but',\n",
              " 'document. used alone, favors common',\n",
              " 'in case they need to',\n",
              " 'generally based upon the quantity',\n",
              " 'chance that someone randomly clicking',\n",
              " 'we have the classes of',\n",
              " 'by salton, wong and yang.',\n",
              " 'p(b|a), or the probability of',\n",
              " 'the highest degrees can be',\n",
              " 'when the subproblem is experienced',\n",
              " 'from its parents. inheritance, at',\n",
              " 'to be calculated again. in',\n",
              " 'multiplied by the page rank',\n",
              " 'on a random link will',\n",
              " 'conditional probabilities in their theories',\n",
              " 'the ibm clever project, and',\n",
              " 'for optimization. therefore, the \"program\"',\n",
              " 'class has all the attributes',\n",
              " 'be in the thousands, to',\n",
              " 'sites that link to that',\n",
              " \"(often called bayes' law after\",\n",
              " \"'dynamic programming' relates to the\",\n",
              " 'order to avoid this, we',\n",
              " 'say that the links from',\n",
              " 'affect the pagerank, such as',\n",
              " 'p(b | a) p(a) /',\n",
              " 'a subclass of the shape',\n",
              " 'the house and office block',\n",
              " 'a powerful mechanism of information',\n",
              " 'may be used is: given',\n",
              " 'vast amounts of statistical evidence.',\n",
              " 'thereby demonstrating the dynamic programming',\n",
              " 'by dividing them into sub-subproblems',\n",
              " 'visits to sites by users.',\n",
              " 'used in probability theory. this',\n",
              " 'so are \"pigs\" & cheaters\".',\n",
              " 'inheritance allows for inheritance from',\n",
              " 'the best websites to suit',\n",
              " 'them into sub-subproblems and so',\n",
              " 'an exhibition is sometimes called',\n",
              " 'document vector. this equation is',\n",
              " 'from 1 and divides this',\n",
              " 'of word matches with the',\n",
              " 'to as polymorphism which is',\n",
              " 'for which dynamic programming may',\n",
              " 'is the “intentional surfer”, where',\n",
              " 'relative frequencies, of each outcome',\n",
              " 'somewhat easier to be dealt',\n",
              " 'important theorem relating conditional probabilities',\n",
              " 'symbolic representation of the world',\n",
              " 'a popularity meter. popularity or',\n",
              " 'the vector is non-zero. many',\n",
              " 'in searches. the second method',\n",
              " 'a solution to a future',\n",
              " 'spamming was implemented. instead google',\n",
              " 'through the use of visibility',\n",
              " 'solution when that subproblem is',\n",
              " 'weights). one of the best',\n",
              " 'a term occurs in the',\n",
              " 'these can then be sub-divided',\n",
              " 'subproblems. 2.solve these problems optimally',\n",
              " 'to be stored. generlisation also',\n",
              " 'is characterized by a vector.',\n",
              " 'like in web mining, homeland',\n",
              " 'positive actually did use drugs',\n",
              " 'subclass and a class can',\n",
              " 'document with the 0.5 pagerank.',\n",
              " 'of pages on the web.',\n",
              " 'the optimal solution to the',\n",
              " 'two random events occuring, and',\n",
              " 'information retrieval. a document has',\n",
              " 'of optimal substructure, overlapping subproblems',\n",
              " 'a method which works out',\n",
              " 'common interpretations of probability. it',\n",
              " 'the number of pages in',\n",
              " 'the probability of a random',\n",
              " 'match\" 3. semantic sensitivity; documents',\n",
              " 'the same underlying principles. it',\n",
              " 'programming which is a similar',\n",
              " 'to ignore links from documents',\n",
              " 'modern meaning. the field was',\n",
              " 'fruit is aq main class',\n",
              " 'model. it is used in',\n",
              " 'go and visit a new',\n",
              " 'action. to say that a',\n",
              " 'examples where we can have',\n",
              " 'methododogy of dynamic programming, which',\n",
              " 'to build up the solutions',\n",
              " 'can look up the solution',\n",
              " 'second b/n and the probability',\n",
              " 'or spoofing pagerank, very little',\n",
              " 'the pagerank of those pages',\n",
              " 'not take into account any',\n",
              " 'for example, in the fibonacci',\n",
              " 'internet; this pagerank? denotes a',\n",
              " 'similar documents are to one',\n",
              " 'would natuarly inheart properities commen',\n",
              " 'as a vector of n',\n",
              " 'b is the probability of',\n",
              " 'lemma called product rule for',\n",
              " 'public void setcolour(color newcolour){ colour',\n",
              " 'or inheritance used within a',\n",
              " 'new features in computer programming',\n",
              " 'documents, such as the www,',\n",
              " 'theorem is a theorem of',\n",
              " 'the complementary event to a).',\n",
              " 'numerical weighting. it is used',\n",
              " \"popular. however, the pr doesn't\",\n",
              " 'every other page linked to',\n",
              " 'be performed on them. inheritance',\n",
              " 'to find relevant documents. the',\n",
              " 'shortest path to the goal',\n",
              " 'meaning that it can look',\n",
              " 'saved. then, when the second',\n",
              " 'page (otherwise known as the',\n",
              " 'products of local and global',\n",
              " 'explain further vector space models,',\n",
              " 'wide web. any page on',\n",
              " 'and document vector were orthogonal',\n",
              " 'develop the basic ideas underlying',\n",
              " 'connects the conditional and marginal',\n",
              " 'in relative terms, once understood.',\n",
              " 'recording what terms are present',\n",
              " 'periodically updated every 3 to',\n",
              " 'the classes become. an example',\n",
              " 'public methods and variables from',\n",
              " 'have a train and aeroplane,',\n",
              " 'extending the vector space model',\n",
              " 'probabilities to random events according',\n",
              " 'these classes to be reused.',\n",
              " 'was added as an attribute',\n",
              " 'terms in the document), where',\n",
              " 'number of instance / total',\n",
              " '(instances of which are called',\n",
              " 'the system uses probability distribution',\n",
              " 'girls, the girls wear skirts',\n",
              " 'girl, and the event b',\n",
              " 'the cosine coefficient, which calculates',\n",
              " 'that t is relevant to',\n",
              " 'has witnessed enough examples, it',\n",
              " 'to add additional forms of',\n",
              " 'is a boy. this is',\n",
              " 'of any size the pagerank',\n",
              " 'that all students have the',\n",
              " 'substructure means that by splitting',\n",
              " 'the \"is a\" relationship between',\n",
              " 'takes the probability of a',\n",
              " 'and to each remaining word,',\n",
              " 'is a way to form',\n",
              " 'links to * dangling links',\n",
              " 'modification and implementation new features',\n",
              " 'to recomputed (leading to computational',\n",
              " \"vocabulary won't be associated, leading\",\n",
              " 'to prevent manipulation, spoofing and',\n",
              " '\"important\" weigh more heavily and',\n",
              " 'may have methods along the',\n",
              " 'new position of a train',\n",
              " 'hierarchy structure, or software engineering',\n",
              " '3. construct an optimal solution,',\n",
              " 'are both kinds of student.',\n",
              " 'be a class variable of',\n",
              " 'and behaviour of the pre-existing',\n",
              " 'a term is a single',\n",
              " 'forms of probability, however it',\n",
              " 'a new object, with different',\n",
              " 'bayes’ law. an example of',\n",
              " 'used for optimisation problems, such',\n",
              " 'be easier to modify since',\n",
              " 'theorem relates the conditional and',\n",
              " 'of sub-sub-problems.sub-problems are then selected',\n",
              " 'or longer phrases. provided that',\n",
              " 'angle itself. a zero value',\n",
              " 'sub-subproblems and so forth, until',\n",
              " 'a number between 0-10 is',\n",
              " 'probability (p) = number of',\n",
              " 'numerical importance to a set',\n",
              " 'programming. the first is the',\n",
              " 'technique used to solve certain',\n",
              " 'of this it means that',\n",
              " 'other factors, e.g. relevance of',\n",
              " 'constant time. overlapping subproblems means',\n",
              " 'on the other hand probability',\n",
              " 'of a binomial distribution. it',\n",
              " 'this approach is that the',\n",
              " 'convention: p(a) is the prior',\n",
              " 'rankings. with reference to this',\n",
              " 'the pagerank?. other link-based ranking',\n",
              " 'optimal solution recursively. 3. compute',\n",
              " '1. characterise structure of an',\n",
              " 'on the number of incoming',\n",
              " 'number of uses and applications',\n",
              " 'a page to give a',\n",
              " 'along time ibm web page',\n",
              " 'classes of objects. a ‘fruit’,',\n",
              " 'compute posterior probabilities given observations',\n",
              " 'solve another problem. since it',\n",
              " 'of is toilet engaged. if',\n",
              " 'frequently used method for the',\n",
              " 'word to describe a set',\n",
              " 'a mass transport class extends',\n",
              " 'and car classes, any car',\n",
              " 'the document whos vector has',\n",
              " \"``and'', ``the'', etc. for sample\",\n",
              " 'probabilty of b given a.',\n",
              " '60%, or 0.6. p(b|a), or',\n",
              " 'to books, journals and other',\n",
              " '(functions) that are common between',\n",
              " 'student is wearing trousers. what',\n",
              " 'or bottom-up in a table.',\n",
              " 'look up the solution when',\n",
              " 'inherited or derived classes inherit',\n",
              " 'relation to the rest of',\n",
              " 'so, the following parsing and',\n",
              " 'meaning that a program can',\n",
              " 'a case is reached which',\n",
              " 'into sub problems, and these',\n",
              " 'child classes in inheritance. inheritance',\n",
              " 'the time, and can identify',\n",
              " 'been defined. these classes have',\n",
              " '(also known as term weights).',\n",
              " 'of the best known schemes',\n",
              " 'for example, a guitar is',\n",
              " 'would be evenly divided between',\n",
              " 'it represents these as vectors',\n",
              " 'solutions of the overall problem.',\n",
              " 'filtering, information retrieval, indexing and',\n",
              " 'a simple case is reached',\n",
              " 'vectors are compared and the',\n",
              " 'there are issues. key words',\n",
              " 'compromised by sparming, google solves',\n",
              " 'your website) link to this',\n",
              " 'a powerful feature.it has been',\n",
              " 'subproblem. 3. construct an optimal',\n",
              " 'new object, with different properties',\n",
              " 'code, named as polymorphism. on',\n",
              " 'in constant time. figure 2.',\n",
              " 'using this three-step process recursively.',\n",
              " 'vector in turn using a',\n",
              " 'theorem states that the probability',\n",
              " 'conjunction with the document vectors',\n",
              " \"bayes' theorem let and be\",\n",
              " 'application was in the smart',\n",
              " 'mathematics and computer science, dynamic',\n",
              " 'methods. in \"dynamic programming\", the',\n",
              " 'encounter with overlapping subproblems, a',\n",
              " 'in a collection of documents,',\n",
              " 'in this way, allows us',\n",
              " 'are ordered from left to',\n",
              " 'to add links for ones',\n",
              " 'visits the page gets. the',\n",
              " 'existing class code in new',\n",
              " 'in the 1940s by richard',\n",
              " 'programming is to find the',\n",
              " 'whenever overlapping subproblems are present:',\n",
              " 'term was first coined in',\n",
              " 'has overlapping subproblems is to',\n",
              " 'new piece of evidence. it',\n",
              " 'frequencies of happening or to',\n",
              " 'engine that assigns a value',\n",
              " 'is the conditional probabilty of',\n",
              " 'was originally used in the',\n",
              " 'represented badly because they have',\n",
              " 'popular is tf-idf weighting. depending',\n",
              " 'can be controlled through the',\n",
              " 'from a theoretical probability value',\n",
              " 'whichever document returns the highest',\n",
              " 'query term did not exist',\n",
              " 'probability of an event happening',\n",
              " '* search keywords must precisely',\n",
              " 'be put into the superclass.',\n",
              " 'to fail. with dynamic programming,',\n",
              " 'of the sites that have',\n",
              " 'later, we can retrieve and',\n",
              " 'search keywords must accurately match',\n",
              " 'of similar code , can',\n",
              " 'of science, it has been',\n",
              " 'a pagerank results from a',\n",
              " \"p(a'), or the probability that\",\n",
              " 'indentifies the success or failure',\n",
              " 'whereas frequentists assign probabilities to',\n",
              " 'a page is based on',\n",
              " 'which is the number of',\n",
              " 'crusade for bayes in high',\n",
              " 'generalization in what is known',\n",
              " 'and undergraduates are both kinds',\n",
              " 'be visualised as a tree',\n",
              " 'of existing code without modification.',\n",
              " 'b, therefore it is also',\n",
              " 'for instance, a finalized schedule',\n",
              " 'control code. inheritance is typically',\n",
              " 'biology to the development of',\n",
              " 'given as 1. p(a), or',\n",
              " 'cannot be rearranged. this means',\n",
              " 'a possible use for a',\n",
              " 'vote. votes cast by pages',\n",
              " 'and therefore considerably reduces computation.',\n",
              " 'financial investment domain. results compare',\n",
              " 'conditional probability, and shows that',\n",
              " 'formula to find the cosine',\n",
              " 'or bottom-up using a table',\n",
              " 'methods along the lines of',\n",
              " 'also be represented as a',\n",
              " 'or a longer phrase. if',\n",
              " 'inheritance means that if such',\n",
              " 'google to measure a popularity',\n",
              " \"won't need a particular solution\",\n",
              " 'is non-zero. to calculate how',\n",
              " 'the foundations of statistics: frequentist',\n",
              " 'inheritance was firstly derived in',\n",
              " 'marginal probability of a. it',\n",
              " 'like the richter scale, the',\n",
              " 'modification, it is intended to',\n",
              " 'support. the pagerank depends on',\n",
              " 'methods of calculating these values,',\n",
              " '0-10 according to its relevance',\n",
              " 'recalculating and therefore considerably reduces',\n",
              " 'refined his method to the',\n",
              " 'was in the smart information',\n",
              " 'instead of this it comes',\n",
              " 'kohler used dynamic programming to',\n",
              " 'using heuristic or information-theoretic criteria,',\n",
              " 'ways of trying to compute',\n",
              " 'secondly, search keywords must accurately',\n",
              " 'differentiated as its subproblems are',\n",
              " 'key words, which contribute to',\n",
              " 'sub problems, and those are',\n",
              " 'theory, the prior and conditional',\n",
              " 'also analyzes the page that',\n",
              " 'rule applies with keywords and',\n",
              " 'random events. for example, a',\n",
              " 'an example here would be',\n",
              " 'code which consequently reduces the',\n",
              " 'calculate various probabilities like joe',\n",
              " 'many attributes which infulance the',\n",
              " 'the dimensionality, if words are',\n",
              " 'method for efficiently solving a',\n",
              " 'to as mathematical programming. richard',\n",
              " 'moreover, there is a q',\n",
              " 'is periodically updated every 3',\n",
              " 'class is a kind of',\n",
              " 'computed optimal subproblems, for the',\n",
              " \"since page and brin's original\",\n",
              " 'is not without its limitations:',\n",
              " 'and one is calculated iteratively',\n",
              " '\"false negative match\". 4. the',\n",
              " 'of vector space model. models',\n",
              " 'the page gets. the method',\n",
              " 'in order to speed up',\n",
              " '0.8. therefore the probability using',\n",
              " 'provided by google as to',\n",
              " 'it is also very accurate.',\n",
              " 'a lot of code which',\n",
              " 'but refuse to add links',\n",
              " 'inheritance means derived a new',\n",
              " 'that the pagerank values converge',\n",
              " 'the amount of links relating',\n",
              " 'percent males as students. the',\n",
              " 'also include some additional features.',\n",
              " 'conditional probability. by combining and',\n",
              " 'the page is about, however,',\n",
              " 'consist of overlapping subproblems and',\n",
              " 'the retrieval efficiency of a',\n",
              " 'other factors influence pagerank. numerous',\n",
              " 'on one of three mathematical',\n",
              " 'p(a | b) = p(b',\n",
              " 'that are ordered from left',\n",
              " 'applied to any collection of',\n",
              " 'might be observed to show',\n",
              " 'from both the ‘postgraduate’ and',\n",
              " 'other pages on the world',\n",
              " 'a binomial distribution. it is',\n",
              " 'uses, as it is not',\n",
              " 'detail to pre-existing classes whilst',\n",
              " 'into more detail. this is',\n",
              " 'help reuse existing code with',\n",
              " 'the way of solving problems',\n",
              " \"1. here we're going to\",\n",
              " 'google internet search engine that',\n",
              " 'highest cosine similarity score is',\n",
              " 'inheriting and specialising - and',\n",
              " 'programming makes use of: overlapping',\n",
              " 'this popularity algorithm is that',\n",
              " 'tool.categorization define as a powerful',\n",
              " 'the flaw that despite the',\n",
              " 'let (4) so is an',\n",
              " 'by the probability of b',\n",
              " 'be used to determine the',\n",
              " 'b. p(a|b) is the conditional',\n",
              " 'used in the smart information',\n",
              " 'example, the shortest path to',\n",
              " 'to the most relevant web',\n",
              " 'of trousers in equal numbers',\n",
              " 'of probability, lean heavily on',\n",
              " 'rather than be recomputed. a',\n",
              " 'small scalar product and a',\n",
              " 'to determine the structure of',\n",
              " 'pagerank results from a \"ballot\"',\n",
              " 'probability of b, and p(b|a)',\n",
              " 'google pagerank algorithm is much',\n",
              " 'the characteristics of the superclass.',\n",
              " 'no modification and are the',\n",
              " 'and variables from both the',\n",
              " 'these links. this means therefore',\n",
              " 'areas where this sort of',\n",
              " 'could be used to compute',\n",
              " 'order in which the events',\n",
              " 'with dynamic programming, we can',\n",
              " 'to give credit to any',\n",
              " 'is essentially a popularity meter.',\n",
              " 'a certain page is generally',\n",
              " 'from the superclass; however any',\n",
              " 'in stack space and number',\n",
              " 'a tree but a dag',\n",
              " 'however this could be abused',\n",
              " 'of offices. however, these personal',\n",
              " 'given that the student is',\n",
              " 'values (namely a small scalar',\n",
              " 'probability of event a given',\n",
              " 'truth renders probable is the',\n",
              " 'calculated either recursively or iteratively.',\n",
              " 'an observer randomly sees a',\n",
              " 'programming has increased enormously. for',\n",
              " 'to compute f5, a naive',\n",
              " '+ pr(c) + pr(d) moreover,',\n",
              " 'the two vectors are compared',\n",
              " 'as students. the female students',\n",
              " 'example, a patient may be',\n",
              " 'the properties and behavior of',\n",
              " \"an official theorem, bayes' theorem\",\n",
              " \"we're going to simply use\",\n",
              " '40% girls as students. the',\n",
              " 'of the time, and can',\n",
              " 'probabilities in terms of beliefs',\n",
              " '\"normalising\" the length. whichever document',\n",
              " 'takes its name from genetic',\n",
              " 'subproblems. 2. recursively use this',\n",
              " 'pr(e). it is known that',\n",
              " 'not considered important. term frequency:',\n",
              " 'optimal solution. secondly to define',\n",
              " 'in information retrieval to determine',\n",
              " 'specialised version). however, object variables',\n",
              " 'second has also happened] is',\n",
              " 'within the set. google assigns',\n",
              " 'and ‘phd student’ as both',\n",
              " 'to a web page there',\n",
              " 'by overriding (replacing) one or',\n",
              " 'of words in the vocabulary',\n",
              " 'visit a new page -',\n",
              " 'subsequent events, the probability of',\n",
              " 'engines by submitting queries relevant',\n",
              " 'user model by counting the',\n",
              " 'b and therefore is considered',\n",
              " 'conventional name: p(a) is the',\n",
              " 'bayes theorem (often called bayes',\n",
              " 'categories;volunteers evaluate, classify, annotate;open directory',\n",
              " 'and hyperlinked set of documents,',\n",
              " 'better in stack space and',\n",
              " 'is typically accomplished either by',\n",
              " 'recomputing optimal solutions to the',\n",
              " 'genuine pagerank. however, much research',\n",
              " 'matter of selecting the document',\n",
              " 'instead of the angle by',\n",
              " 'observed is a girl, and',\n",
              " 'site will be. this method',\n",
              " 'top-most superclasses. this can save',\n",
              " 'then (5) (6) but this',\n",
              " 'define as a powerful feature.it',\n",
              " 'programming problems that exhibit the',\n",
              " 'vector space model, the term',\n",
              " 'it is using this to',\n",
              " 'of subproblems, these can then',\n",
              " 'is the prior probability or',\n",
              " 'model for representing objects (although',\n",
              " 'and so on, until they',\n",
              " 'a numeric weighting from 0-10',\n",
              " 'pagerank. the pagerank theory holds',\n",
              " 'new methods on top of',\n",
              " 'for a vector space model',\n",
              " 'in such an architecture even',\n",
              " '= f1 + f2 and',\n",
              " 'the other hand probability theory',\n",
              " 'get bored and then switch',\n",
              " 'the probability, at any step,',\n",
              " 'and conquer, however is differentiated',\n",
              " 'therefore considerably reduces computation. it',\n",
              " 'for `real-world scenarios like in',\n",
              " 'can be in the thousands,',\n",
              " 'of this it comes from',\n",
              " 'existing code to be used',\n",
              " 'sees a random student, meaning',\n",
              " 'into subproblems, these themselves may',\n",
              " 'coloured balls with 25 red',\n",
              " 'is used in order to',\n",
              " 'of events on the other',\n",
              " 'of evidence and their models',\n",
              " '(leading to computational efficiency). dynamic',\n",
              " 'development, the number of uses',\n",
              " 'randomly clicking on links will',\n",
              " 'in the system, adding it',\n",
              " 'solve this problem, web pages',\n",
              " 'that the terms appear in',\n",
              " 'wearing trousers given that the',\n",
              " 'useful tool.categorization define as a',\n",
              " 'automated information retrieval systems are',\n",
              " 'the top-down approach, the problem',\n",
              " 'as follows: probability (p) =',\n",
              " 'of problem for which dynamic',\n",
              " 'forward by salton, wong and',\n",
              " 'pick the best overall path.',\n",
              " 'represent a hierarchy between classes',\n",
              " 'available for use. by using',\n",
              " 'and office block are both',\n",
              " 'to random events according to',\n",
              " 'calculating these values, sometimes known',\n",
              " 'recursion. the main problem is',\n",
              " 'pages on the world wide',\n",
              " 'it contains general characteristics for',\n",
              " \"a formal theorem, bayes' theorem\",\n",
              " 'be specified high up in',\n",
              " \"way that a 'term' is\",\n",
              " 'from a distance; all they',\n",
              " 'path can be found, thereby',\n",
              " 'for probabilities. provided that p(b)',\n",
              " 'factor, pagerank of a single',\n",
              " 'its value is non-zero. to',\n",
              " 'science and pseudosience, and other',\n",
              " 'pre-existing classes, which are referred',\n",
              " 'much more complex than this,',\n",
              " 'f5, a naive approach to',\n",
              " 'each also has its own',\n",
              " 'space. results will range from',\n",
              " 'derived from mathematical programming which',\n",
              " 'be formed by this process',\n",
              " 'is assigned to each webpage',\n",
              " 'the hits algorithm invented by',\n",
              " 'values (aka (term) weights) have',\n",
              " 'the ‘postgraduate’ node by adding',\n",
              " '\"apple\", \"orange\", \"mango\" and many',\n",
              " 'disadvantage is of pagerank algorithm',\n",
              " 'transport. at first glance, a',\n",
              " 'documents, such as the world',\n",
              " 'of \"apple\", \"orange\", \"mango\" and',\n",
              " 'has been also used in',\n",
              " 'that the query and document',\n",
              " 'vector is compared to each',\n",
              " 'to de-emphasize the e_ect of',\n",
              " 'all unique words from the',\n",
              " 'a specific page, usually bypassing',\n",
              " 'the pagerank of any page',\n",
              " 'event to a). this is',\n",
              " 'on bayesian probability and frequentist',\n",
              " \"'b'. p(a | b) =\",\n",
              " 'which has no links to',\n",
              " 'solved in advance and then',\n",
              " 'page * outbound links (forward',\n",
              " 'assumptions of document similarities theory,',\n",
              " 'parts of code that are',\n",
              " 'and memoization. it has no',\n",
              " 'node by adding two extra',\n",
              " 'terms are in the document.',\n",
              " 'and so only one calculation',\n",
              " 'means that the new class,',\n",
              " 'criteria. the criteria may include',\n",
              " 'co-ed school having 60% boys',\n",
              " 'accomplished either by overriding one',\n",
              " 'a way of understanding how',\n",
              " 'similiarity betweeen two pages or',\n",
              " 'an important feature in object',\n",
              " 'their parent classes, which can',\n",
              " 'of objects. it can be',\n",
              " 'of pages, dampening factor, pagerank',\n",
              " 'of programming being a helper',\n",
              " 'when the second route is',\n",
              " 'factors influence pagerank. numerous academic',\n",
              " 'was firstly derived in 1967.',\n",
              " 'solutions of subproblems, these can',\n",
              " 'and specialising - and sometimes',\n",
              " 'variety of uses. each different',\n",
              " 'a host of information retrieval',\n",
              " 'which means that no term',\n",
              " 'keyword spamming was implemented. instead',\n",
              " 'accurate. joe records all of',\n",
              " 'theorem is given by p(a|b)',\n",
              " 'is an algebraic model for',\n",
              " 'in google directory: pagerank: sort',\n",
              " \"symptoms. bayes' theorem can be\",\n",
              " 'to be a subclass of',\n",
              " 'of a finalized schedule of',\n",
              " 'space scoring; a pivotal step',\n",
              " 'to a subproblem the first',\n",
              " 'theorem\" or \"bayes\\' rule\", or',\n",
              " 'a plant. inheritance is typically',\n",
              " 'solving the given problem. some',\n",
              " 'libraries use ir systems to',\n",
              " 'to each other. bayesians describe',\n",
              " 'to a wider group provided',\n",
              " 'our already-computed solution. this approach',\n",
              " 'webpage generaly gives a good',\n",
              " 'optimal subproblems, for the original',\n",
              " 'space modelling is useful there',\n",
              " 'he had refined this to',\n",
              " 'ranking of 0-10 according to',\n",
              " 'always be greater than or',\n",
              " 'will be non-zero in the',\n",
              " 'and variables, whilst also creating',\n",
              " 'link farms which have recursive',\n",
              " 'have name, address and other',\n",
              " 'is in a keyword search',\n",
              " 'belief is governed by the',\n",
              " 'in the smart information retrieval',\n",
              " 'sights, the higher the rank',\n",
              " 'meaning that all students have',\n",
              " 'programming is useful is in',\n",
              " 'depends on the pagerank rating',\n",
              " 'from part time hours worked,',\n",
              " 'documents of any size the',\n",
              " 'programmerers when developing web applications..when',\n",
              " 'a page is linked to',\n",
              " 'uses a link analysis algorithm',\n",
              " 'relation between science and pseudosience,',\n",
              " 'a similar word used for',\n",
              " 'to tackle this problem you',\n",
              " 'example, a program could exist',\n",
              " 'exhibit the properties of overlapping',\n",
              " 'the world, there are many',\n",
              " 'one is calculated iteratively according',\n",
              " 'of inheritance. therefore inheritance can',\n",
              " 'page that links to a,',\n",
              " 'hours worked, as the full',\n",
              " 'represent a hierarchy amongst classes',\n",
              " 'the rest of the sites',\n",
              " '\"cow\" is a generalization of',\n",
              " 'etc. conversely, since apples are',\n",
              " 'of” relationship. for example, a',\n",
              " 'retrieval, but each also has',\n",
              " 'probability of a. it does',\n",
              " 'method of solving the problems',\n",
              " 'this will find the difference',\n",
              " 'a separate term. if a',\n",
              " 'key to dynamic programming is',\n",
              " 'can be formed by this',\n",
              " 'to a page is seen',\n",
              " 'not represented in the vector',\n",
              " 'from your page to others.',\n",
              " \"where ' denotes a complementary\",\n",
              " 'ways in which probabilities should',\n",
              " 'is the total number of',\n",
              " 'mathematicians use the word to',\n",
              " 'in java all attributes and',\n",
              " 'simply 1. this meant that',\n",
              " 'higher ranking for their less-relevant',\n",
              " 'link analysis algorithm employed by',\n",
              " 'joining to them and get',\n",
              " 'law after rev thomas bayes)',\n",
              " 'created. one of the most',\n",
              " 'a methodology of the solution',\n",
              " 'view called polymorphism, where many',\n",
              " 'pagerank of those pages that',\n",
              " 'these are then used in',\n",
              " 'the users web browser window.',\n",
              " 'optimal solutions. the steps required',\n",
              " 'rating, this increases the rating',\n",
              " 'pagerank relies on the uniquely',\n",
              " 'inheritance has another view called',\n",
              " 'sometimes called a program. programming',\n",
              " 'the optimal path in the',\n",
              " 'statistics and physics. there is',\n",
              " 'the program. inheritance, therefore, can',\n",
              " 'documents, each document can be',\n",
              " 'probability. p(b|a) is the conditional',\n",
              " 'in a mathematical \"bag\" structure,',\n",
              " 'probability value on a logarithmic',\n",
              " 'gathered in great volume can',\n",
              " 'problems that make use of',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN98qJCSO_bY"
      },
      "source": [
        "### STEP - 2: Min-Hashing (40 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4iXdSWpO_bZ"
      },
      "source": [
        "# ***************************************************NEW***********************************************************\n",
        "# Generate Hash functions - \n",
        "    # We use (ax + b) mod N formula to permute shingle index\n",
        "    # where a,b are random numbers, N total index size, and x is the index\n",
        "# We need to do L permutations - In other words we need to have L permutations (lists) of new indexes\n",
        "# Following function takes total index size N and L as arguments\n",
        "    # And returns L new lists of size N\n",
        "    \n",
        "def get_hash_functions(N,L):\n",
        "    hash_functions = []\n",
        "    \n",
        "    for itr in range(L):\n",
        "        a=randrange(1,400)\n",
        "        b=randrange(1,400)\n",
        "        \n",
        "        new_hash_function = []\n",
        "        for i in range(N):\n",
        "            new_hash_function.append((a * i + b) % N)\n",
        "        \n",
        "        hash_functions.append(new_hash_function)\n",
        "    return hash_functions\n",
        "        \n",
        "# test\n",
        "# hash_functions = get_hash_functions(5000,50)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STTOMho2O_bZ"
      },
      "source": [
        "# Type your code here to generate all L hash functions\n",
        "# Generate hash functions only for shingle index created for k=5\n",
        "#L = 50\n",
        "L = [50,100,200,500,1000]                         #created a list of L values given in quetion\n",
        "N = len(uniquek5shingles)                         #taking number of unique shingles as length of hashfunction\n",
        "allHFunList = []\n",
        "for i in L:\n",
        "  allHFunList.append(get_hash_functions(N,i))     #calling hash function each L"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF103XqTO_ba"
      },
      "source": [
        "# Type your code here to get the final signature matrix S here\n",
        "\n",
        "#below function will generate signature matric for each L ranging from 50, 100, 200, 500 and 1000\n",
        "def getSignatureVectors(shingleIndex, L, hashfuncs):   \n",
        "  signdict = {}                                   #created dictionary to store file name as key and signature vector as value.\n",
        "  for key in shingleIndex:                        #for each file in shingle index\n",
        "    s1=[np.inf for n in range(L)]                 #Initializing each value in signature vector as infinity\n",
        "    for s in uniquek5shingles:                    #for each shingle in all unque shingles\n",
        "      if s in shingleIndex[key]:                  #for each shingle in the file\n",
        "        index=uniquek5shinglesList.index(s)       #getting the index from unique shingle list \n",
        "        for i in range(L):                        #for each of the hash function\n",
        "          if hashfuncs[i][index]<s1[i]:           #checking the hash value with signature vector\n",
        "            s1[i]=hashfuncs[i][index]             #assigning hashvalue if it less than already exsisted value\n",
        "    signdict[key] = s1                            #assigning the signature vector to the dictionary\n",
        "  return signdict\n",
        "\n",
        "Suspicioussignatures = []                         #created an empty list to store all suspicious signature vectors for all L's \n",
        "for i in range(len(allHFunList)):\n",
        "  signMat = getSignatureVectors(shingleIndex5, L[i], allHFunList[i])\n",
        "  Suspicioussignatures.append(signMat)            #appending to the list\n",
        "#Suspicioussignatures[0]"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBpiRdGhO_bb",
        "outputId": "d5dd1575-529d-44c1-f753-a07578f9be50"
      },
      "source": [
        "# Type your code here to do the fact check \n",
        "#      with any one query document in the 'Original' directory\n",
        "\n",
        "original = 'Original/orig_taska.txt'    #took file a in as it is mentioned any file in quetion, you can change it any file in original directory\n",
        "\n",
        "# STEP-1: Generate 5-shingles \n",
        "    # (if any shingles are not present in your shingle index, simply ignore them)\n",
        "\n",
        "#below lines will generate 5 shingle index for the file given above\n",
        "k5ShigleIndextaskdict = {}\n",
        "k5ShigleIndextask = set()\n",
        "with open(original, \"r\",encoding ='utf8',errors='ignore') as filename:\n",
        "  pList = filename.read()\n",
        "  wList = pList.split()\n",
        "k = 5\n",
        "for i in range(len(wList)-k+1):\n",
        "  w = wList[i:i + k]\n",
        "  x = ' '.join(w).lower()\n",
        "  k5ShigleIndextask.add(x)\n",
        "#print(k5ShigleIndextask)\n",
        "k5ShigleIndextaskdict[original.split('/')[1]] = list(k5ShigleIndextask)\n",
        "    \n",
        "    \n",
        "# STEP-2: Generate signature vector from L hash functions\n",
        "\n",
        "taskcSignMatrix = []                    #generating signatue vector for the above given original file for all L values\n",
        "for i in range(len(allHFunList)):\n",
        "  signMat = getSignatureVectors(k5ShigleIndextaskdict, L[i], allHFunList[i])\n",
        "  taskcSignMatrix.append(signMat)\n",
        "\n",
        "\n",
        "# STEP-3: Calculate Jaccard similarity of signature vector of orginal doc.\n",
        "    # and all other documents \n",
        "    \n",
        "t = 0.85              #change the threshold to get more or less pairs of files.\n",
        "\n",
        "dictTaskJSAllLs = {}                                 #created an empty dictionaly to store all the jaccard similarity greater than given t\n",
        "for l in range(len(L)):                              #looping through all L value range\n",
        "  dictTaskJSeachL = {}                               #dictionary to store all file pairs as key and jaccard similarity as value\n",
        "  for i in Suspicioussignatures[l]:                  #looping through each suspicious vectors from each L \n",
        "    for j in taskcSignMatrix[l]:                     #looping through original file vectors from each L\n",
        "      count =0                                       #initializing temporary count variable to check jaccard similarity \n",
        "      for r in range(L[l]):                          #looping through each value in signature vector\n",
        "        if Suspicioussignatures[l][i][r] == taskcSignMatrix[l][j][r]:   #comparing values from suspicious signature vector to original signature vector \n",
        "          count+=1                                   #incrementing the count if same\n",
        "      js = count/L[l]                                #dividing the count with Hash functions to get jaccard similarity\n",
        "      if js> t:                                      #checking whether Jaccard similarity is greater than threshold\n",
        "        dictTaskJSeachL[str(i)+' ,'+str(j)] = js     #creating a dictioanary with key as pair of file and value as its Jaccard similarity\n",
        "  dictTaskJSAllLs[L[l]] = dictTaskJSeachL            #dictionary to store key as L value and value as all the pairs with JS greater than JS\n",
        "\n",
        "# STEP-4: Facts Checks\n",
        "# For each L = {50,100,200,500,1000}, report all documents (file_names) below that have Jaccard similarity > t=0.85\n",
        "# Sort the documents in decreasing order of the Jaccard similarity\n",
        "\n",
        "#below loop will print Jaccard similarity in decreasing order for each L value\n",
        "for i in dictTaskJSAllLs: \n",
        "  print('\\033[1m'+'Jaccard Similarity for L = '+str(i)+' in decreasing order for t = '+str(t)+'\\033[0m')\n",
        "  if len(dictTaskJSAllLs[i])>0:\n",
        "    orderedValuesJS = dict(sorted(dictTaskJSAllLs[i].items(), key=lambda itm: itm[1], reverse = True))\n",
        "    for j in orderedValuesJS:\n",
        "      print(j+'-> '+'\\033[1m'+str(orderedValuesJS[j])+'\\033[0m')\n",
        "  else:\n",
        "    print('No document found with jaccard similarity greater than ',t)\n",
        "  print('\\n')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mJaccard Similarity for L = 50 in decreasing order for t = 0.85\u001b[0m\n",
            "g4pC_taska.txt ,orig_taska.txt-> \u001b[1m0.92\u001b[0m\n",
            "g0pE_taska.txt ,orig_taska.txt-> \u001b[1m0.86\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1mJaccard Similarity for L = 100 in decreasing order for t = 0.85\u001b[0m\n",
            "No document found with jaccard similarity greater than  0.85\n",
            "\n",
            "\n",
            "\u001b[1mJaccard Similarity for L = 200 in decreasing order for t = 0.85\u001b[0m\n",
            "g0pE_taska.txt ,orig_taska.txt-> \u001b[1m0.89\u001b[0m\n",
            "g4pC_taska.txt ,orig_taska.txt-> \u001b[1m0.86\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1mJaccard Similarity for L = 500 in decreasing order for t = 0.85\u001b[0m\n",
            "g0pE_taska.txt ,orig_taska.txt-> \u001b[1m0.874\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1mJaccard Similarity for L = 1000 in decreasing order for t = 0.85\u001b[0m\n",
            "g0pE_taska.txt ,orig_taska.txt-> \u001b[1m0.88\u001b[0m\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDer6QL2MvXT"
      },
      "source": [
        "originalSignatures = []                           #created an empty list to store all original signature vectors for all L's \n",
        "for i in range(len(allHFunList)):\n",
        "  signMat = getSignatureVectors(OrignalIndex5, L[i], allHFunList[i])\n",
        "  originalSignatures.append(signMat)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMevhDC8EQt_",
        "outputId": "03c29b53-6f23-46ea-aed4-f9ed7a4c81e5"
      },
      "source": [
        "#here we are taking all the original files and finding jaccard similarity\n",
        "dictJSAllLs = {} \n",
        "for l in range(len(L)):\n",
        "  dictJSeachL = {}\n",
        "  for i in Suspicioussignatures[l]: \n",
        "    for j in originalSignatures[l]:\n",
        "      count =0\n",
        "      for r in range(L[l]):\n",
        "        if Suspicioussignatures[l][i][r] == originalSignatures[l][j][r]:\n",
        "          count+=1\n",
        "      js = count/L[l]\n",
        "      if js> t:\n",
        "        dictJSeachL[str(i)+' ,'+str(j)] = js\n",
        "  dictJSAllLs[L[l]] = dictJSeachL\n",
        "\n",
        "for i in dictJSAllLs: \n",
        "  print('\\033[1m'+'Jaccard Similarity for L = '+str(i)+' in decreasing order for t = '+str(t)+'\\033[0m')\n",
        "  if len(dictJSAllLs[i])>0:\n",
        "    orderedValuesJS = dict(sorted(dictJSAllLs[i].items(), key=lambda itm: itm[1], reverse = True))\n",
        "    for j in orderedValuesJS:\n",
        "      print(j+'-> '+'\\033[1m'+str(orderedValuesJS[j])+'\\033[0m')\n",
        "  else:\n",
        "    print('No document found with jaccard similarity greater than ',t)\n",
        "  print('\\n')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mJaccard Similarity for L = 50 in decreasing order for t = 0.85\u001b[0m\n",
            "g4pC_taska.txt ,orig_taska.txt-> \u001b[1m0.92\u001b[0m\n",
            "g0pE_taska.txt ,orig_taska.txt-> \u001b[1m0.86\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1mJaccard Similarity for L = 100 in decreasing order for t = 0.85\u001b[0m\n",
            "No document found with jaccard similarity greater than  0.85\n",
            "\n",
            "\n",
            "\u001b[1mJaccard Similarity for L = 200 in decreasing order for t = 0.85\u001b[0m\n",
            "g0pE_taska.txt ,orig_taska.txt-> \u001b[1m0.89\u001b[0m\n",
            "g4pC_taska.txt ,orig_taska.txt-> \u001b[1m0.86\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1mJaccard Similarity for L = 500 in decreasing order for t = 0.85\u001b[0m\n",
            "g0pE_taska.txt ,orig_taska.txt-> \u001b[1m0.874\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1mJaccard Similarity for L = 1000 in decreasing order for t = 0.85\u001b[0m\n",
            "g0pE_taska.txt ,orig_taska.txt-> \u001b[1m0.88\u001b[0m\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS2tN2ZiO_bd"
      },
      "source": [
        "### STEP - 3: LSH (30 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj-cqpgdO_bd"
      },
      "source": [
        "# Type your code here to hash signature matrix into B buckets\n",
        "# Use the technique to split the signature matrix into b bands of r rows\n",
        "# Convert only the signature matrix generated with L=1000\n",
        "\n",
        "b = 50\n",
        "r = 20\n",
        "B = 199\n",
        "a = random.sample(range(50), r)     #with generate random 20 numbers in 50 "
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7uTbZqewzfy"
      },
      "source": [
        "# Type your code here to do generate candidate documents\n",
        "# Follow all steps from STEP - 2 fact check (except the Jaccard similarity part)\n",
        "\n",
        "#below function will hash each band b of r rows of a file and places into one bucket of 199 buckets \n",
        "def getBuckets(matrixSign, b, B):\n",
        "  buckets = []                                 #initializing empty list to store buckets of dictionries for each band b\n",
        "  for i in range(b):                           #looping through all bands\n",
        "    bucdict = {}                              #initializing empty dictionary to store bucket number as key and files as list in value\n",
        "    for j in matrixSign:                      #looping through signature vector for each file \n",
        "      hashValue = (np.sum((a)*(np.array(matrixSign[j][i*r:(i*r)+r])))) % B    #here it multiplies each row from band to random number and percentile with B(199) to get bucket number\n",
        "      if hashValue in list(bucdict.keys()):    #placing the file in the bucket using dictionary and appending to the list\n",
        "        bucdict[hashValue].append(j) \n",
        "      else:\n",
        "        bucdict[hashValue] = list([j])\n",
        "    buckets.append(bucdict)\n",
        "  return buckets\n",
        "#print(Suspicioussignatures[4])\n",
        "#here are using already created suspicious files signature and for L=1000\n",
        "suspiciousBuckets = getBuckets(Suspicioussignatures[4],b,B) #this will hash files from signature vectors to any of the 199 buckets\n",
        "#print(suspiciousBuckets)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahi4Otl0O_be"
      },
      "source": [
        "# STEP - 1: Split each original document signature vector into b bands of r rows\n",
        "\n",
        "#this step is covered in by calling getBuckets() in below function \n",
        "\n",
        "# STEP - 2: Hash using the same hash functions created for \n",
        "    # signature matrix hashing (in the previous cell)\n",
        "\n",
        "#calling getbuckets will hash each orinal to any of the 199 buckets\n",
        "originalBuckets = getBuckets(originalSignatures[4],b,B)   #we are using originalSignatures \n",
        "#originalBuckets\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2--AwXsO_be"
      },
      "source": [
        "# Type your code here to do the fact check\n",
        "# Calculate Jaccard similarity of the oiginal document with only \n",
        "    # candidate documents\n",
        "\n",
        "#below function will check if any suspicious bucket hash is same as original bucket hash    \n",
        "candidatesdict = {}\n",
        "for i in range(b):                                              #for each band\n",
        "  candidates = [value for value in suspiciousBuckets[i] if value in originalBuckets[i]]  #checking if same value is present respective band\n",
        "  #print(candidates)\n",
        "  for j in candidates:                                #looping through all the candidates, which are found in same bucket\n",
        "    for o in originalBuckets[i][j]:                   #for each original document \n",
        "      if o in list(candidatesdict.keys()):            #creating dictionary to store candidate documents, key as original doc, value as set of candidates\n",
        "        candidatesdict[o].update(set(suspiciousBuckets[i][j])) \n",
        "      else:\n",
        "        candidatesdict[o] = set(suspiciousBuckets[i][j])\n",
        "#print(candidatesdict)\n",
        "\n",
        "#this loop is to create nested dictionary with key as original file and value is a dictionary of (key as all suspicious documents and value is Jaccard Similarity)\n",
        "L1000dictJS = {}                                   #creating a dictionary to store all the jaccard similarity of L=1000\n",
        "forFalNegUsage = set()                             #this is used while doing false negatives\n",
        "for j in originalSignatures[4]:                   #looping the same way as dicussed above to get Jaccard Similarity\n",
        "  suspDictJS = {}\n",
        "  for i in Suspicioussignatures[4]:\n",
        "    count =0\n",
        "    for r in range(L[4]):\n",
        "      if Suspicioussignatures[4][i][r] == originalSignatures[4][j][r]:\n",
        "        count+=1\n",
        "    js = count/L[4]\n",
        "    if js > t:\n",
        "      forFalNegUsage.add(i)                       #adding all documents which has jaccard similarity with any original document greater than threshold t\n",
        "    suspDictJS[i] = js                            #creating a nested dictionary with key as original file and value is a dictionary of (key as all suspicious documents and value is Jaccard Similarity)\n",
        "  L1000dictJS[j] = suspDictJS\n",
        "\n",
        "#L1000dictJS"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "uhqBgWvWO_be"
      },
      "source": [
        "Report all documents (file_names) below that have Jaccard similarity > t=0.85\n",
        "Sort the documents in decreasing order of the Jaccard similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSDIApihO_bf",
        "outputId": "d25dc9d7-deba-48a3-8369-0bd605538310"
      },
      "source": [
        "dictCandJSeachL1000 = {}                         #dictionary to store all candidate documents with Jaccard Similarity > threshold t\n",
        "dictCandJSeachL1000FalPos = {}                   #dictionary to store all suspicious documents mapped to different original documents     \n",
        "candDocsSetlessThant = set()                     #set to store candidate documents with Jaccard Similarity < threshold t\n",
        "candDocsSetmoreThant = set()                     #set to store candidate documents with Jaccard Similarity > threshold t\n",
        "candDocsSet = set()                              #set to store all candidate documents \n",
        "for i in candidatesdict:                          #looping through all the candidate documents with keys as original documents\n",
        "  for j in list(candidatesdict[i]):               #looping through all the values, those candidates(suspicious documents) found aboove\n",
        "    if L1000dictJS[i][j] >= t:                    #checking jaccard similarity\n",
        "      dictCandJSeachL1000[j+', '+i] = L1000dictJS[i][j] #dictionary storing key as pair and value Jaccard similarity>t\n",
        "      candDocsSetmoreThant.add(j)                  \n",
        "    else:\n",
        "      dictCandJSeachL1000FalPos[j+', '+i] = L1000dictJS[i][j]  #dictionary storing key as pair and value Jaccard similarity<t\n",
        "      candDocsSetlessThant.add(j)\n",
        "    candDocsSet.add(j)    #all candidate documents\n",
        "\n",
        "print('\\033[1m'+'The number of candidate documents are: '+str(len(candDocsSet))+'\\033[0m')\n",
        "#printing all the candidate documents in decending order of Jaccard Similarity\n",
        "print('\\033[1m'+'Jaccard Similarity for candidate documents in decreasing order for given t>='+str(t)+'\\033[0m')\n",
        "if len(dictCandJSeachL1000)>0:                    \n",
        "    orderedValuesJS = dict(sorted(dictCandJSeachL1000.items(), key=lambda itm: itm[1], reverse = True))\n",
        "    for j in orderedValuesJS:\n",
        "      print(j+'-> '+'\\033[1m'+str(orderedValuesJS[j])+'\\033[0m')\n",
        "    print('\\n')\n",
        "else:\n",
        "  print('No document found with jaccard similarity greater than ',t)\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mThe number of candidate documents are: 68\u001b[0m\n",
            "\u001b[1mJaccard Similarity for candidate documents in decreasing order for given t>=0.85\u001b[0m\n",
            "g0pE_taska.txt, orig_taska.txt-> \u001b[1m0.88\u001b[0m\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "xlLuKtAyO_bf"
      },
      "source": [
        "Report the list of false positives and false negatives below\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o9lLOTRC0Dp"
      },
      "source": [
        "#False Positives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnQN0t4p_dqt",
        "outputId": "8baf92a6-041c-4afe-c065-be8a5adc212f"
      },
      "source": [
        "#Printing all documents together combining suspicious documents together which fell in same of different original documents\n",
        "falsePosdocs = candDocsSet.difference(candDocsSetmoreThant) #subtracting the set of documents with JS less than t and from all candidate documents set \n",
        "print('\\033[1m'+'The number of false positive documents are: '+str(len(falsePosdocs))+'\\033[0m')\n",
        "print('\\033[1m'+'The documents in false positives are: '+'\\033[0m')\n",
        "print(falsePosdocs)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mThe number of false positive documents are: 67\u001b[0m\n",
            "\u001b[1mThe documents in false positives are: \u001b[0m\n",
            "{'g4pB_taskd.txt', 'g3pA_taskc.txt', 'g1pA_taskd.txt', 'g4pE_taskb.txt', 'g3pC_taska.txt', 'g4pE_taskc.txt', 'g3pC_taske.txt', 'g2pE_taske.txt', 'g4pB_taske.txt', 'g0pE_taskc.txt', 'g1pA_taskb.txt', 'g4pD_taska.txt', 'g1pD_taskc.txt', 'g4pD_taskb.txt', 'g0pD_taske.txt', 'g0pE_taskb.txt', 'g0pA_taskd.txt', 'g2pC_taske.txt', 'g2pB_taske.txt', 'g3pB_taska.txt', 'g3pC_taskd.txt', 'g1pB_taska.txt', 'g3pB_taskc.txt', 'g4pD_taske.txt', 'g0pE_taskd.txt', 'g1pA_taskc.txt', 'g2pA_taskd.txt', 'g0pB_taska.txt', 'g2pC_taskc.txt', 'g2pE_taskb.txt', 'g3pC_taskb.txt', 'g2pA_taske.txt', 'g2pB_taskc.txt', 'g2pA_taskb.txt', 'g4pD_taskd.txt', 'g0pB_taskb.txt', 'g0pA_taska.txt', 'g0pD_taskd.txt', 'g3pC_taskc.txt', 'g0pA_taskb.txt', 'g0pA_taskc.txt', 'g0pC_taskc.txt', 'g3pB_taske.txt', 'g4pC_taskd.txt', 'g0pD_taskb.txt', 'g1pD_taskd.txt', 'g2pC_taskb.txt', 'g0pC_taskd.txt', 'g0pC_taske.txt', 'g1pB_taskd.txt', 'g4pC_taska.txt', 'g2pA_taskc.txt', 'g0pB_taskc.txt', 'g4pB_taskc.txt', 'g1pB_taskb.txt', 'g4pB_taskb.txt', 'g1pD_taske.txt', 'g0pD_taska.txt', 'g0pA_taske.txt', 'g0pB_taskd.txt', 'g4pC_taskc.txt', 'g4pE_taskd.txt', 'g4pE_taska.txt', 'g1pA_taska.txt', 'g3pA_taske.txt', 'g1pB_taske.txt', 'g0pE_taske.txt'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26WCVhZoO_bf",
        "outputId": "fc0df686-66fe-4d28-971d-20fa3ee251c1"
      },
      "source": [
        "#Here I am printing all the suspicious documents that hashed to same bucket of original separately \n",
        "print('\\033[1m'+'printing candidate documents with each original file separatly\\nFalse positives: Candidate documents that fell in same bucket as original document but has jaccard similarity less than '+str(t)+'\\033[0m')\n",
        "#print(len(dictCandJSeachL1000FalPos))\n",
        "if len(dictCandJSeachL1000FalPos)>0:\n",
        "    orderedValuesJS = dict(sorted(dictCandJSeachL1000FalPos.items(), key=lambda itm: itm[1], reverse = True))\n",
        "    for j in orderedValuesJS:\n",
        "      print(j+'-> '+'\\033[1m'+str(orderedValuesJS[j])+'\\033[0m')\n",
        "    print('\\n')\n",
        "else:\n",
        "  print('No document found')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mprinting candidate documents with each original file separatly\n",
            "False positives: Candidate documents that fell in same bucket as original document but has jaccard similarity less than 0.85\u001b[0m\n",
            "g4pC_taska.txt, orig_taska.txt-> \u001b[1m0.833\u001b[0m\n",
            "g4pC_taskd.txt, orig_taskd.txt-> \u001b[1m0.603\u001b[0m\n",
            "g4pB_taske.txt, orig_taske.txt-> \u001b[1m0.522\u001b[0m\n",
            "g3pC_taska.txt, orig_taska.txt-> \u001b[1m0.326\u001b[0m\n",
            "g0pC_taskd.txt, orig_taskd.txt-> \u001b[1m0.285\u001b[0m\n",
            "g3pB_taske.txt, orig_taske.txt-> \u001b[1m0.189\u001b[0m\n",
            "g4pB_taskd.txt, orig_taskd.txt-> \u001b[1m0.169\u001b[0m\n",
            "g3pA_taskc.txt, orig_taskc.txt-> \u001b[1m0.134\u001b[0m\n",
            "g0pB_taskd.txt, orig_taskd.txt-> \u001b[1m0.116\u001b[0m\n",
            "g0pA_taskd.txt, orig_taskd.txt-> \u001b[1m0.053\u001b[0m\n",
            "g4pB_taske.txt, orig_taskb.txt-> \u001b[1m0.053\u001b[0m\n",
            "g2pB_taske.txt, orig_taskd.txt-> \u001b[1m0.046\u001b[0m\n",
            "g3pA_taske.txt, orig_taske.txt-> \u001b[1m0.043\u001b[0m\n",
            "g1pA_taskc.txt, orig_taskc.txt-> \u001b[1m0.04\u001b[0m\n",
            "g2pA_taskb.txt, orig_taske.txt-> \u001b[1m0.04\u001b[0m\n",
            "g3pC_taske.txt, orig_taske.txt-> \u001b[1m0.039\u001b[0m\n",
            "g4pD_taskb.txt, orig_taske.txt-> \u001b[1m0.039\u001b[0m\n",
            "g2pC_taske.txt, orig_taskb.txt-> \u001b[1m0.038\u001b[0m\n",
            "g2pA_taske.txt, orig_taskd.txt-> \u001b[1m0.037\u001b[0m\n",
            "g3pB_taskc.txt, orig_taska.txt-> \u001b[1m0.037\u001b[0m\n",
            "g0pB_taskb.txt, orig_taskd.txt-> \u001b[1m0.035\u001b[0m\n",
            "g0pB_taska.txt, orig_taskb.txt-> \u001b[1m0.035\u001b[0m\n",
            "g3pA_taskc.txt, orig_taskd.txt-> \u001b[1m0.034\u001b[0m\n",
            "g0pB_taska.txt, orig_taska.txt-> \u001b[1m0.034\u001b[0m\n",
            "g4pE_taskd.txt, orig_taske.txt-> \u001b[1m0.034\u001b[0m\n",
            "g4pE_taska.txt, orig_taske.txt-> \u001b[1m0.034\u001b[0m\n",
            "g0pA_taskc.txt, orig_taskb.txt-> \u001b[1m0.034\u001b[0m\n",
            "g1pA_taskd.txt, orig_taske.txt-> \u001b[1m0.032\u001b[0m\n",
            "g3pC_taskb.txt, orig_taske.txt-> \u001b[1m0.032\u001b[0m\n",
            "g2pA_taskb.txt, orig_taskc.txt-> \u001b[1m0.031\u001b[0m\n",
            "g4pB_taskc.txt, orig_taskb.txt-> \u001b[1m0.031\u001b[0m\n",
            "g4pD_taskd.txt, orig_taska.txt-> \u001b[1m0.03\u001b[0m\n",
            "g1pB_taskb.txt, orig_taske.txt-> \u001b[1m0.03\u001b[0m\n",
            "g3pB_taskc.txt, orig_taskb.txt-> \u001b[1m0.03\u001b[0m\n",
            "g1pA_taska.txt, orig_taskb.txt-> \u001b[1m0.03\u001b[0m\n",
            "g3pB_taskc.txt, orig_taskd.txt-> \u001b[1m0.029\u001b[0m\n",
            "g4pD_taske.txt, orig_taskd.txt-> \u001b[1m0.029\u001b[0m\n",
            "g0pB_taskc.txt, orig_taske.txt-> \u001b[1m0.029\u001b[0m\n",
            "g1pA_taskc.txt, orig_taske.txt-> \u001b[1m0.029\u001b[0m\n",
            "g1pA_taskb.txt, orig_taska.txt-> \u001b[1m0.028\u001b[0m\n",
            "g0pA_taska.txt, orig_taskd.txt-> \u001b[1m0.027\u001b[0m\n",
            "g2pE_taske.txt, orig_taskd.txt-> \u001b[1m0.027\u001b[0m\n",
            "g3pB_taskc.txt, orig_taske.txt-> \u001b[1m0.027\u001b[0m\n",
            "g2pE_taskb.txt, orig_taske.txt-> \u001b[1m0.027\u001b[0m\n",
            "g2pA_taske.txt, orig_taskb.txt-> \u001b[1m0.027\u001b[0m\n",
            "g1pA_taska.txt, orig_taskc.txt-> \u001b[1m0.026\u001b[0m\n",
            "g1pA_taskd.txt, orig_taska.txt-> \u001b[1m0.026\u001b[0m\n",
            "g1pA_taskd.txt, orig_taskc.txt-> \u001b[1m0.025\u001b[0m\n",
            "g0pC_taske.txt, orig_taskc.txt-> \u001b[1m0.025\u001b[0m\n",
            "g2pC_taskc.txt, orig_taska.txt-> \u001b[1m0.025\u001b[0m\n",
            "g1pB_taske.txt, orig_taskb.txt-> \u001b[1m0.025\u001b[0m\n",
            "g4pE_taskc.txt, orig_taskd.txt-> \u001b[1m0.024\u001b[0m\n",
            "g1pD_taskd.txt, orig_taskd.txt-> \u001b[1m0.024\u001b[0m\n",
            "g1pD_taskd.txt, orig_taskc.txt-> \u001b[1m0.024\u001b[0m\n",
            "g4pE_taskd.txt, orig_taska.txt-> \u001b[1m0.024\u001b[0m\n",
            "g4pD_taskd.txt, orig_taskb.txt-> \u001b[1m0.024\u001b[0m\n",
            "g3pB_taska.txt, orig_taskd.txt-> \u001b[1m0.023\u001b[0m\n",
            "g1pA_taska.txt, orig_taskd.txt-> \u001b[1m0.023\u001b[0m\n",
            "g4pE_taskd.txt, orig_taskc.txt-> \u001b[1m0.023\u001b[0m\n",
            "g1pD_taskc.txt, orig_taskb.txt-> \u001b[1m0.023\u001b[0m\n",
            "g0pE_taska.txt, orig_taskc.txt-> \u001b[1m0.022\u001b[0m\n",
            "g1pB_taskd.txt, orig_taskc.txt-> \u001b[1m0.022\u001b[0m\n",
            "g1pB_taskb.txt, orig_taska.txt-> \u001b[1m0.022\u001b[0m\n",
            "g4pB_taskb.txt, orig_taska.txt-> \u001b[1m0.022\u001b[0m\n",
            "g1pD_taskc.txt, orig_taske.txt-> \u001b[1m0.022\u001b[0m\n",
            "g1pD_taske.txt, orig_taska.txt-> \u001b[1m0.021\u001b[0m\n",
            "g3pC_taskb.txt, orig_taska.txt-> \u001b[1m0.021\u001b[0m\n",
            "g0pC_taskc.txt, orig_taske.txt-> \u001b[1m0.021\u001b[0m\n",
            "g0pC_taskc.txt, orig_taskc.txt-> \u001b[1m0.02\u001b[0m\n",
            "g2pB_taskc.txt, orig_taskc.txt-> \u001b[1m0.02\u001b[0m\n",
            "g3pB_taska.txt, orig_taskc.txt-> \u001b[1m0.02\u001b[0m\n",
            "g4pE_taskb.txt, orig_taske.txt-> \u001b[1m0.02\u001b[0m\n",
            "g0pD_taska.txt, orig_taske.txt-> \u001b[1m0.02\u001b[0m\n",
            "g2pC_taskb.txt, orig_taske.txt-> \u001b[1m0.02\u001b[0m\n",
            "g4pB_taske.txt, orig_taskc.txt-> \u001b[1m0.019\u001b[0m\n",
            "g0pE_taskb.txt, orig_taskc.txt-> \u001b[1m0.019\u001b[0m\n",
            "g4pD_taske.txt, orig_taska.txt-> \u001b[1m0.019\u001b[0m\n",
            "g2pE_taskb.txt, orig_taska.txt-> \u001b[1m0.019\u001b[0m\n",
            "g0pA_taske.txt, orig_taske.txt-> \u001b[1m0.019\u001b[0m\n",
            "g3pC_taskb.txt, orig_taskd.txt-> \u001b[1m0.018\u001b[0m\n",
            "g0pA_taskb.txt, orig_taskc.txt-> \u001b[1m0.018\u001b[0m\n",
            "g3pB_taske.txt, orig_taskc.txt-> \u001b[1m0.018\u001b[0m\n",
            "g3pC_taskc.txt, orig_taska.txt-> \u001b[1m0.018\u001b[0m\n",
            "g2pC_taskb.txt, orig_taska.txt-> \u001b[1m0.018\u001b[0m\n",
            "g1pB_taskd.txt, orig_taske.txt-> \u001b[1m0.018\u001b[0m\n",
            "g1pD_taskd.txt, orig_taskb.txt-> \u001b[1m0.018\u001b[0m\n",
            "g4pD_taska.txt, orig_taskc.txt-> \u001b[1m0.017\u001b[0m\n",
            "g0pA_taska.txt, orig_taska.txt-> \u001b[1m0.017\u001b[0m\n",
            "g0pC_taskd.txt, orig_taska.txt-> \u001b[1m0.017\u001b[0m\n",
            "g2pA_taskc.txt, orig_taskd.txt-> \u001b[1m0.016\u001b[0m\n",
            "g0pE_taske.txt, orig_taskd.txt-> \u001b[1m0.016\u001b[0m\n",
            "g4pE_taskc.txt, orig_taskb.txt-> \u001b[1m0.016\u001b[0m\n",
            "g4pC_taskc.txt, orig_taskd.txt-> \u001b[1m0.015\u001b[0m\n",
            "g2pA_taskd.txt, orig_taskc.txt-> \u001b[1m0.015\u001b[0m\n",
            "g2pC_taskb.txt, orig_taskc.txt-> \u001b[1m0.015\u001b[0m\n",
            "g1pB_taska.txt, orig_taskd.txt-> \u001b[1m0.014\u001b[0m\n",
            "g0pE_taskb.txt, orig_taska.txt-> \u001b[1m0.014\u001b[0m\n",
            "g3pC_taska.txt, orig_taskd.txt-> \u001b[1m0.013\u001b[0m\n",
            "g0pE_taskc.txt, orig_taskd.txt-> \u001b[1m0.012\u001b[0m\n",
            "g3pC_taska.txt, orig_taskc.txt-> \u001b[1m0.011\u001b[0m\n",
            "g0pD_taske.txt, orig_taskb.txt-> \u001b[1m0.011\u001b[0m\n",
            "g0pB_taska.txt, orig_taskc.txt-> \u001b[1m0.009\u001b[0m\n",
            "g0pE_taskd.txt, orig_taska.txt-> \u001b[1m0.009\u001b[0m\n",
            "g1pD_taskc.txt, orig_taskc.txt-> \u001b[1m0.008\u001b[0m\n",
            "g3pC_taskd.txt, orig_taske.txt-> \u001b[1m0.008\u001b[0m\n",
            "g0pD_taskb.txt, orig_taska.txt-> \u001b[1m0.007\u001b[0m\n",
            "g0pE_taskd.txt, orig_taskd.txt-> \u001b[1m0.006\u001b[0m\n",
            "g0pD_taskd.txt, orig_taskd.txt-> \u001b[1m0.004\u001b[0m\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLIUGfqJC7w6"
      },
      "source": [
        "#False Negatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL7wuPTI-thx",
        "outputId": "37813712-c759-43e3-fbe8-6168fac4816f"
      },
      "source": [
        "falNegList = []  #initializing empty list to add false negatives\n",
        "for i in forFalNegUsage:              #looping though all the suspicious documents with Jaccard Similarity> threshold\n",
        "  if i not in candDocsSet:            #if not present in candidate documents then adding to the set        \n",
        "    falNegList.append(i) \n",
        "#printing false negatives\n",
        "if len(falNegList)>0:\n",
        "  print('\\033[1m'+'The number of false negatives documents are: '+str(len(falNegList))+'\\033[0m')\n",
        "  print('\\033[1m'+'The documents in false positives are: '+'\\033[0m')\n",
        "  print(falNegList)\n",
        "else:\n",
        "  print('No document found')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No document found\n"
          ]
        }
      ]
    }
  ]
}